{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce290cd4",
   "metadata": {},
   "source": [
    "Informasi datang dalam berbagai bentuk dan ukuran. Salah satu bentuk penting adalah **data terstruktur**, di mana terdapat relasi teratur antar entitas. Misalnya, ketika kita ingin mencari tempat kerja, bisa jadi kita mungkin tertarik pada hubungan antara perusahaan dan lokasi. Mengingat perusahaan tertentu, kita mengidentifikasi lokasi di mana bisnis dijalankan. Sebaliknya, berdasarkan lokasi, kita bisa mengetahui perusahaan mana yang melakukan bisnis di lokasi tersebut. \n",
    "\n",
    "Perhatikan tabel berikut:\n",
    "\n",
    "| OrgName             | LocationName |\n",
    "|---------------------|--------------|\n",
    "| Omnicom             | New York     |\n",
    "| DDB Needham         | New York     |\n",
    "| Kaplan Thaler Group | New York     |\n",
    "| BBDO South          | Atlanta      |\n",
    "| Georgia-Pacific     | Atlanta      |\n",
    "\n",
    "Jika tabel di atas diubah ke dalam bentuk list atau tuple, maka muncul pertanyaan,\"Perusahaan mana yang lokasinya berada di Atlanta?\" Dengan bantuan python, kita bisa menuliskan:\n",
    "```python\n",
    "print([e1 for (e1,rel,e2) in data_kota if e2 == 'Atlanta'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "601cc022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBDO South', 'Georgia-Pasific']\n"
     ]
    }
   ],
   "source": [
    "data_kota = [\n",
    "    ('Omnicom','IN','New York'),\n",
    "    ('DDB Needham','IN','New York'),\n",
    "    ('Kaplan Thaler Group','IN','New York'),\n",
    "    ('BBDO South','IN','Atlanta'),\n",
    "    ('Georgia-Pasific','IN','Atlanta'),\n",
    "]\n",
    "\n",
    "hasil = [e1 for (e1,rel,e2) in data_kota if e2 == 'Atlanta']\n",
    "print(hasil)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3271d08",
   "metadata": {},
   "source": [
    "Dengan model data berupa list, tentu akan mudah dalam mencari kata. Akan tetapi, bila teksnya seperti berikut:\n",
    "\n",
    "\"*The fourth Wells account moving to another agency is the packaged paper-products division of Georgia-Pacific Corp., which arrived at Wells only last fall. Like Hertz and the History Channel, it is also leaving for an Omnicom-owned agency, the BBDO South unit of BBDO Worldwide. BBDO South in Atlanta, which handles corporate advertising for Georgia-Pacific, will assume additional duties for brands like Angel Soft toilet tissue and Sparkle paper towels, said Ken Haldin, a spokesman for Georgia-Pacific in Atlanta.*\"\n",
    "\n",
    "bagaimana cara mengambil informasi terkait perusahaan dan lokasinya? pertanyaan ini akan terjawab pada poin 3 yang membahas tentang Named-Entity Recognition (NER).\n",
    "\n",
    "Secara umum, arsitektur dari ekstraksi informasi adalah seperti Gambar 1\n",
    "![image.png](images/alur.png)\n",
    "*Gambar 1. Arsitektur dan alur ekstraksi informasi*\n",
    "\n",
    "Pada Gambar 1, tahapan *sentence segmentation* adalah proses mengubah teks menjadi token di mana tiap token adalah satu kalimat. Tahapan ini sudah dituntaskan pada Praktikum 1. Tahapan sisanya, kita bahas pada Praktikum ke-2 ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c8d8b",
   "metadata": {},
   "source": [
    "# Tagging Part-of-Speech (POS Tagging) #\n",
    "\n",
    "**Part of speech** adalah istilah untuk grammar pada susunan kata yang dipakai seperti noun, verbs, adjective, adverbs, etc. Dalam NLP, POS Tagging adalah proses penandaan pada tiap kata berdasarkan *part of speech*. \n",
    "\n",
    "Sebagai contoh POS Tagging, kita gunakan kembali variabel `kalimat_token`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f77cb1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/oddy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2bb19264",
   "metadata": {},
   "outputs": [],
   "source": [
    "kalimat = \"The striped bats are hanging on their feet in a dangerous place\"\n",
    "kalimat_token = word_tokenize(kalimat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d54418fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('dangerous', 'JJ'), ('place', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kalimat_token_pos_tagged = nltk.pos_tag(kalimat_token)\n",
    "print(kalimat_token_pos_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccfa0c0",
   "metadata": {},
   "source": [
    "Output dari adalah\n",
    "\n",
    "```cmd\n",
    "[('The', 'DT'), ('striped', 'JJ'), ('bats', 'NNS'), ('are', 'VBP'), ('hanging', 'VBG'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('for', 'IN'), ('best', 'JJS')]\n",
    "```\n",
    "Setelah melihat isinya, mungkin kalian kebingungan. Tenang saja. Untuk mengetahui singkatan-singkatan tersebut, jalankan kode berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "08afe52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /home/oddy/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f76ca",
   "metadata": {},
   "source": [
    "#### Penjelasan kode ####\n",
    "1. `nltk.download('averaged_perceptron_tagger')` digunakan untuk mengunduh corpus untuk POS Tagging\n",
    "1. `nltk.pos_tag(kalimat_token)` digunakan untuk melabel/tagging token dari teks\n",
    "1. `nltk.download('tagsets')` digunakan untuk mengunduh corpus tagsets\n",
    "1. `nltk.help.upenn_tagset()` digunakan untuk menampilkan daftar istilah dalam POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389dcf5c",
   "metadata": {},
   "source": [
    "# Chunking #\n",
    "\n",
    "## Mungkin kalian bertanya, apa sih kegunaan dari POS Tagging? ##\n",
    "\n",
    "Dari tahapan awal hingga POS Tagging, yang kita lakukan hanyalah memproses token yang berisi satu kata. Bagaimana jika ada kumpulan kata dengan makna satu atau yang biasa disebut dengan frasa? Nah, di sinilah peran dari POS Tagging. Dengan adanya POS Tagging, kita bisa membuat 'rumus' untuk memilah suatu frasa. \n",
    "Contoh frasa dalam bahasa Inggris, yaitu: 'a dangerouse place', 'a beautiful mind', etc. \n",
    "\n",
    "Jika menggunakan tokenisasi langsung, maka teks 'a dangerous place' akan dipecah menjadi tiga token. Padahal, teks frasa memiliki satu arti tertentu yang tidak bisa dipisahkan. \n",
    "\n",
    "## Bagaimana cara mencari frasa dari teks? ##\n",
    "\n",
    "Di NLTK ada fitur yang disebut sebagai 'Chunk Grammar'. Chunk Grammar (CG) adalah kumpulan susunan grammar berdasarkan POS Tagging. Pada dasarnya, CG menggunakan regular expression atau Regex.\n",
    "\n",
    "Contoh dari rumus CG dalam mencari frasa adalah\n",
    "`grammar = \"NP: {<DT>?<JJ>*<NN>}\"`\n",
    "\n",
    "di mana `NP` adalah Noun Phrase atau frasa kata benda, sedangkan `DT` adalah determiner, `JJ` adalah adjective, dan `NN` adalah Noun atau kata benda. Tanda `?` memiliki arti bahwa `DT` itu bersifat opsional atau tidak wajib ada, sedangkan `*` berarti bahwa `JJ` bisa lebih dari satu. Untuk lebih jelasnya, mari kita praktikkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6cbf8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3fa7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = chunk_parser.parse(kalimat_token_pos_tagged)\n",
    "#tree.draw() Khusus desktop user, silakan uncomment kode ini jika ingin melihat hasilnya. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "868acc55",
   "metadata": {},
   "source": [
    "Hasil dari `tree.draw()` adalah seperti pada Gambar 2\n",
    "![image.png](images/hirarki.png)\n",
    "*Hirarki Frasa*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523f9b7",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) #\n",
    "\n",
    "Named Entity (NE) adalah frasa kata benda yang menunjukkan lokasi, nama orang, nama organisasi, dan sebagainya. Dengan NER, kita bisa menemukan NE dari dalam teks dan juga menentukan jenis NE-nya. Tujuan dari NER adalah untuk mengidentifikasi semua penyebutan tekstual dari entitas. NER dapat dipecah menjadi dua tugas, pertama mengidentifikasi batas-batas NE dan mengidentifikasi jenisnya. Selain berfungsi untuk identifikasi **relasi** dalam **Ekstraksi Informasi** NER juga digunakan pada tugas-tugas lain. Misalnya, di Question Answering (QA), informasi yang diambil tidaklah keseluruhan halaman, tetapi hanya bagian-bagian yang berisi jawaban atas pertanyaan pengguna. \n",
    "\n",
    "**Sekarang misalkan pertanyaannya adalah Siapa Presiden pertama Indonesia?**, dan salah satu dokumen yang diambil berisi bagian berikut:\n",
    "\n",
    "\"*The National Monument is the most prominent structure in Jakarta and one of the city's early attractions. It was built and initiated by Soekarno, who led the country to independence and then became its first President.*\"\n",
    "\n",
    "Sebelum melakukan NER, kita lakukan preprocessing dulu terhadap teks yang akan diproses. Adapun fungsi dari preprocess adalah:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b47d5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_teks(teks):\n",
    "    teks = nltk.sent_tokenize(teks)\n",
    "    list_token = []\n",
    "    for word in teks:\n",
    "        kalimat = word_tokenize(word)\n",
    "        list_token.append(kalimat)\n",
    "    \n",
    "    return list_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "57e481b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGANIZATION National Monument\n",
      "GPE Jakarta\n",
      "PERSON Soekarno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/oddy/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/oddy/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# langkah satu\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "# langkah dua\n",
    "contoh_teks = \"The National Monument is the most prominent structure \" \\\n",
    "\"in Jakarta and one of the city's early attractions. \"\\\n",
    "\"It was built and initiated by Soekarno, who led the\"\\\n",
    "\", who led the country to independence and then became its first President. \"\n",
    "\n",
    "# langkah tiga\n",
    "for word in preprocess_teks(contoh_teks):\n",
    "    pos = nltk.pos_tag(word)\n",
    "    chunks = nltk.ne_chunk(pos)\n",
    "\n",
    "    # langkah empat\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk,'label'):\n",
    "            print(chunk.label(),' '.join(c[0] for c in chunk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d8539",
   "metadata": {},
   "source": [
    "Jika Anda mengamati output di atas, NER menemukan total tiga entitas, yaitu ORGANIZATION, GPE (lokasi), dan PERSON (nama), yhanya dengan tiga baris kode python. Mari kita amati kode yang telah terjadi.\n",
    "\n",
    "1. `nltk.download('maxent_ne_chunker')`\n",
    "1. `nltk.download('words')`\n",
    "1. `contoh_teks`\n",
    "```python\n",
    "contoh_teks = \"The National Monument is the most prominent structure \" \\\n",
    "\"in Jakarta and one of the city's early attractions. \"\\\n",
    "\"It was built and initiated by Soekarno, who led the\"\\\n",
    "\", who led the country to independence and then became its first President. \"\n",
    "```\n",
    "\n",
    "Langkah satu dan dua sangat mudah; kami telah mengunduh modul yang diperlukan dan mendefinisikan `contoh_teks` sebagai variabel python.\n",
    "\n",
    "Pada langkah ketiga, kita memanggil fungsi `preprocess_teks` untuk mengubah `contoh_teks` menjadi bentuk token yang sudah di POS Tagging. Output dari fungsi `preprocess_teks` digunakan untuk langkah tiga dalam menghasilkan NER, yaitu dengan menggunakan `chunks = nltk.ne_chunk(pos)`. Variabel `chunks`, berisi semua token yang telah berisi NER.\n",
    "\n",
    "Langkah keempat sebenarnya sangat sederhana, yaitu hanya memunculkan data yang ada labelnya. Dari langkah empat ini, yang dihasilkan NER dari `contoh_teks` adalah\n",
    "```cmd\n",
    "ORGANIZATION National Monument\n",
    "GPE Jakarta\n",
    "PERSON Soekarno\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b026839",
   "metadata": {},
   "source": [
    "Demikian praktikum 2, semoga lancar dan penuh berkah belajarnya.\n",
    "\n",
    "# Referensi #\n",
    "\n",
    "1. N. Indurkhya and F. J. Damerau, Handbook of Natural Language Processing. CRC Press, 2010.\n",
    "1. S. Bird, E. Klein, and E. Loper, Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit. O’Reilly Media, 2009.\n",
    "1. https://www.nltk.org/index.html00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
